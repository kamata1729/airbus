{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils as utils\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as data\n",
    "import torchvision.utils as v_utils\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001124c7.jpg</td>\n",
       "      <td>1 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>1 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001b1832.jpg</td>\n",
       "      <td>1 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00052ed46.jpg</td>\n",
       "      <td>1 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000532683.jpg</td>\n",
       "      <td>1 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId EncodedPixels\n",
       "0  0001124c7.jpg           1 2\n",
       "1  000194a2d.jpg           1 2\n",
       "2  0001b1832.jpg           1 2\n",
       "3  00052ed46.jpg           1 2\n",
       "4  000532683.jpg           1 2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('./sample_submission.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003e153.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000155de5.jpg</td>\n",
       "      <td>264661 17 265429 33 266197 33 266965 33 267733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00021ddc3.jpg</td>\n",
       "      <td>101361 1 102128 3 102896 4 103663 6 104430 9 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00021ddc3.jpg</td>\n",
       "      <td>95225 2 95992 5 96760 7 97527 9 98294 9 99062 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00021ddc3.jpg</td>\n",
       "      <td>74444 4 75212 4 75980 4 76748 4 77517 3 78285 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId                                      EncodedPixels\n",
       "0  00003e153.jpg                                                NaN\n",
       "1  000155de5.jpg  264661 17 265429 33 266197 33 266965 33 267733...\n",
       "2  00021ddc3.jpg  101361 1 102128 3 102896 4 103663 6 104430 9 1...\n",
       "3  00021ddc3.jpg  95225 2 95992 5 96760 7 97527 9 98294 9 99062 ...\n",
       "4  00021ddc3.jpg  74444 4 75212 4 75980 4 76748 4 77517 3 78285 ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks = pd.read_csv('./train_ship_segmentations.csv')\n",
    "masks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    #nan check\n",
    "    if mask_rle != mask_rle:\n",
    "        img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "        return img.reshape(shape)\n",
    "    \n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T  # Needed to align to RLE direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(image_path):\n",
    "    img_masks = masks.loc[masks['ImageId'] == image_path.split('/')[-1], 'EncodedPixels'].tolist()\n",
    "\n",
    "    # Take the individual ship masks and create a single mask array for all ships\n",
    "    masks_all = np.zeros((768, 768))\n",
    "    for mask in img_masks:\n",
    "        masks_all += rle_decode(mask)\n",
    "    masks_all = np.minimum(masks_all, 1)*255\n",
    "    tmp = np.array((masks_all, masks_all, masks_all), dtype=np.uint8)\n",
    "    tmp = tmp.transpose(1,2,0)\n",
    "    \n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rle_decode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-33f74a4fec1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mall_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m768\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_masks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mall_masks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrle_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mall_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rle_decode' is not defined"
     ]
    }
   ],
   "source": [
    "ImageId = '3a8e20d83.jpg'\n",
    "\n",
    "img = cv2.imread('./train/' + ImageId)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img_masks = masks.loc[masks['ImageId'] == ImageId, 'EncodedPixels'].tolist()\n",
    "\n",
    "# Take the individual ship masks and create a single mask array for all ships\n",
    "all_masks = np.zeros((768, 768))\n",
    "for mask in img_masks:\n",
    "    all_masks += rle_decode(mask)\n",
    "    \n",
    "all_masks = np.minimum(all_masks, 1)\n",
    "fig, axarr = plt.subplots(1, 3, figsize=(15, 40))\n",
    "axarr[0].axis('off')\n",
    "axarr[1].axis('off')\n",
    "axarr[2].axis('off')\n",
    "axarr[0].imshow(img)\n",
    "axarr[1].imshow(all_masks)\n",
    "axarr[2].imshow(img)\n",
    "axarr[2].imshow(all_masks, alpha=0.4)\n",
    "plt.tight_layout(h_pad=0.1, w_pad=0.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AirbusDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.image_paths = os.listdir(root_dir)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.root_dir, self.image_paths[idx])\n",
    "        image = cv2.imread(image_path)\n",
    "        masked_img = create_mask(image_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            masked_img = self.transform(masked_img)\n",
    "        return image, masked_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "img_size = 256\n",
    "\n",
    "train_dataset = AirbusDataset(root_dir='./train/', transform=transforms.Compose([\n",
    "                                            transforms.ToPILImage(),\n",
    "                                            transforms.Resize(size=img_size),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            ]))\n",
    "train_batch = data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                            shuffle=True, num_workers=2)\n",
    "test_data = AirbusDataset(root_dir='./test/', transform=transforms.Compose([\n",
    "                                            transforms.ToPILImage(),\n",
    "                                            transforms.Resize(size=img_size),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_dim,out_dim,act_fn):\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(in_dim,out_dim, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(out_dim),\n",
    "        act_fn,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def conv_trans_block(in_dim,out_dim,act_fn):\n",
    "    model = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_dim,out_dim, kernel_size=3, stride=2, padding=1,output_padding=1),\n",
    "        nn.BatchNorm2d(out_dim),\n",
    "        act_fn,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def maxpool():\n",
    "    pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "    return pool\n",
    "\n",
    "\n",
    "def conv_block_2(in_dim,out_dim,act_fn):\n",
    "    model = nn.Sequential(\n",
    "        conv_block(in_dim,out_dim,act_fn),\n",
    "        nn.Conv2d(out_dim,out_dim, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(out_dim),\n",
    "    )\n",
    "    return model    \n",
    "\n",
    "\n",
    "def conv_block_3(in_dim,out_dim,act_fn):\n",
    "    model = nn.Sequential(\n",
    "        conv_block(in_dim,out_dim,act_fn),\n",
    "        conv_block(out_dim,out_dim,act_fn),\n",
    "        nn.Conv2d(out_dim,out_dim, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(out_dim),\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetGenerator(nn.Module):\n",
    "\n",
    "\tdef __init__(self,in_dim,out_dim,num_filter):\n",
    "\t\tsuper(UnetGenerator,self).__init__()\n",
    "\t\tself.in_dim = in_dim\n",
    "\t\tself.out_dim = out_dim\n",
    "\t\tself.num_filter = num_filter\n",
    "\t\tact_fn = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "\t\tprint(\"\\n------Initiating U-Net------\\n\")\n",
    "\n",
    "\t\tself.down_1 = conv_block_2(self.in_dim,self.num_filter,act_fn)\n",
    "\t\tself.pool_1 = maxpool()\n",
    "\t\tself.down_2 = conv_block_2(self.num_filter*1,self.num_filter*2,act_fn)\n",
    "\t\tself.pool_2 = maxpool()\n",
    "\t\tself.down_3 = conv_block_2(self.num_filter*2,self.num_filter*4,act_fn)\n",
    "\t\tself.pool_3 = maxpool()\n",
    "\t\tself.down_4 = conv_block_2(self.num_filter*4,self.num_filter*8,act_fn)\n",
    "\t\tself.pool_4 = maxpool()\n",
    "\n",
    "\t\tself.bridge = conv_block_2(self.num_filter*8,self.num_filter*16,act_fn)\n",
    "\n",
    "\t\tself.trans_1 = conv_trans_block(self.num_filter*16,self.num_filter*8,act_fn)\n",
    "\t\tself.up_1 = conv_block_2(self.num_filter*16,self.num_filter*8,act_fn)\n",
    "\t\tself.trans_2 = conv_trans_block(self.num_filter*8,self.num_filter*4,act_fn)\n",
    "\t\tself.up_2 = conv_block_2(self.num_filter*8,self.num_filter*4,act_fn)\n",
    "\t\tself.trans_3 = conv_trans_block(self.num_filter*4,self.num_filter*2,act_fn)\n",
    "\t\tself.up_3 = conv_block_2(self.num_filter*4,self.num_filter*2,act_fn)\n",
    "\t\tself.trans_4 = conv_trans_block(self.num_filter*2,self.num_filter*1,act_fn)\n",
    "\t\tself.up_4 = conv_block_2(self.num_filter*2,self.num_filter*1,act_fn)\n",
    "\n",
    "\t\tself.out = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(self.num_filter,self.out_dim,3,1,1),\n",
    "\t\t\tnn.Tanh(),\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self,input):\n",
    "\t\tdown_1 = self.down_1(input)\n",
    "\t\tpool_1 = self.pool_1(down_1)\n",
    "\t\tdown_2 = self.down_2(pool_1)\n",
    "\t\tpool_2 = self.pool_2(down_2)\n",
    "\t\tdown_3 = self.down_3(pool_2)\n",
    "\t\tpool_3 = self.pool_3(down_3)\n",
    "\t\tdown_4 = self.down_4(pool_3)\n",
    "\t\tpool_4 = self.pool_4(down_4)\n",
    "\n",
    "\t\tbridge = self.bridge(pool_4)\n",
    "\n",
    "\t\ttrans_1 = self.trans_1(bridge)\n",
    "\t\tconcat_1 = torch.cat([trans_1,down_4],dim=1)\n",
    "\t\tup_1 = self.up_1(concat_1)\n",
    "\t\ttrans_2 = self.trans_2(up_1)\n",
    "\t\tconcat_2 = torch.cat([trans_2,down_3],dim=1)\n",
    "\t\tup_2 = self.up_2(concat_2)\n",
    "\t\ttrans_3 = self.trans_3(up_2)\n",
    "\t\tconcat_3 = torch.cat([trans_3,down_2],dim=1)\n",
    "\t\tup_3 = self.up_3(concat_3)\n",
    "\t\ttrans_4 = self.trans_4(up_3)\n",
    "\t\tconcat_4 = torch.cat([trans_4,down_1],dim=1)\n",
    "\t\tup_4 = self.up_4(concat_4)\n",
    "\n",
    "\t\tout = self.out(up_4)\n",
    "\n",
    "\t\treturn out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------Initiating U-Net------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recon_loss_func = nn.MSELoss()\n",
    "generator = nn.DataParallel(UnetGenerator(3,3,64),device_ids=[0]).cuda()\n",
    "\n",
    "lr = 0.002\n",
    "gen_optimizer = torch.optim.Adam(generator.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  1.5584\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type UnetGenerator. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  9.9601\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "0\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  1.8720\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "0\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  1.9106\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "0\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  3.2335\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "0\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  8.7643\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "0\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  7.9865\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "0\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  4.8248\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "0\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  5.9784\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epoch = 10\n",
    "file = open('./unet_mse_loss', 'w')\n",
    "for i in range(epoch):\n",
    "    for _, (images,img_masks) in enumerate(train_batch):\n",
    "        gen_optimizer.zero_grad()\n",
    "\n",
    "        x = Variable(images).cuda(0)\n",
    "        y_ = Variable(img_masks).cuda(0).float()\n",
    "        y = generator.forward(x)\n",
    "        \n",
    "        loss = recon_loss_func(y,y_)\n",
    "        file.write(str(loss)+\"\\n\")\n",
    "        loss.backward()\n",
    "        gen_optimizer.step()\n",
    "\n",
    "        if _ % 400 ==0:\n",
    "            print(i)\n",
    "            print(loss)\n",
    "            v_utils.save_image(x.cpu().data,\"./result/original_image_{}_{}.png\".format(i,_))\n",
    "            v_utils.save_image(y_.cpu().data,\"./result/label_image_{}_{}.png\".format(i,_))\n",
    "            v_utils.save_image(y.cpu().data,\"./result/gen_image_{}_{}.png\".format(i,_))\n",
    "            torch.save(generator,'./model/unet_{}_{}.pkl'.format(i,_))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
