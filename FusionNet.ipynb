{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils as utils\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as data\n",
    "import torchvision.utils as v_utils\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003e153.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000155de5.jpg</td>\n",
       "      <td>264661 17 265429 33 266197 33 266965 33 267733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00021ddc3.jpg</td>\n",
       "      <td>101361 1 102128 3 102896 4 103663 6 104430 9 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00021ddc3.jpg</td>\n",
       "      <td>95225 2 95992 5 96760 7 97527 9 98294 9 99062 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00021ddc3.jpg</td>\n",
       "      <td>74444 4 75212 4 75980 4 76748 4 77517 3 78285 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId                                      EncodedPixels\n",
       "0  00003e153.jpg                                                NaN\n",
       "1  000155de5.jpg  264661 17 265429 33 266197 33 266965 33 267733...\n",
       "2  00021ddc3.jpg  101361 1 102128 3 102896 4 103663 6 104430 9 1...\n",
       "3  00021ddc3.jpg  95225 2 95992 5 96760 7 97527 9 98294 9 99062 ...\n",
       "4  00021ddc3.jpg  74444 4 75212 4 75980 4 76748 4 77517 3 78285 ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks  =  pd.read_csv ('./train_ship_segmentations.csv')\n",
    "masks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    #nan check\n",
    "    if mask_rle != mask_rle:\n",
    "        img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "        return img.reshape(shape).T\n",
    "    \n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T  # Needed to align to RLE direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(image_path):\n",
    "    img_masks = masks.loc[masks['ImageId'] == image_path.split('/')[-1], 'EncodedPixels'].tolist()\n",
    "\n",
    "    # Take the individual ship masks and create a single mask array for all ships\n",
    "    masks_all = np.zeros((768, 768))\n",
    "    for mask in img_masks:\n",
    "        masks_all += rle_decode(mask)\n",
    "    masks_all = np.minimum(masks_all, 1)*255\n",
    "    tmp = np.array((masks_all, masks_all, masks_all), dtype=np.uint8)\n",
    "    tmp = tmp.transpose(1,2,0)\n",
    "    \n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_runlength(convert_image):\n",
    "    convert_image = cv2.resize(convert_image, (768, 768))\n",
    "    flatten = np.where((convert_image.T).flatten() == 1)[0]\n",
    "    runlength = \"\"\n",
    "    count = 0\n",
    "    if len(flatten) == 1:\n",
    "        runlength = str(flatten[0]) + \" 1\"\n",
    "        return runlength\n",
    "    for i in range(len(flatten)):\n",
    "        if i == 0:\n",
    "            runlength = runlength +  str(flatten[i]) + \" \"\n",
    "            count = 1\n",
    "        elif i == len(flatten)-1:\n",
    "            if flatten[i] == flatten[i-1]+1:\n",
    "                count += 1\n",
    "                runlength = runlength + str(count)\n",
    "            else:\n",
    "                runlength = runlength + str(count) + \" \" + str(flatten[i]) + \" 1\"\n",
    "        else:\n",
    "            if flatten[i] == flatten[i-1]+1:\n",
    "                count += 1\n",
    "            else:\n",
    "                runlength = runlength + str(count) + \" \" + str(flatten[i]) + \" \"\n",
    "                count = 1\n",
    "    return runlength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AirbusDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.image_paths = os.listdir(root_dir)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.root_dir, self.image_paths[idx])\n",
    "        image = cv2.imread(image_path)\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        masked_img = create_mask(image_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            masked_img = self.transform(masked_img)\n",
    "        return image, masked_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AirbusTestDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.image_paths = os.listdir(root_dir)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.root_dir, self.image_paths[idx])\n",
    "        image = cv2.imread(image_path)\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.image_paths[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "img_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AirbusDataset(root_dir='./train/', transform=transforms.Compose([\n",
    "                                            transforms.ToPILImage(),\n",
    "                                            transforms.Resize(size=img_size),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            ]))\n",
    "train_batch = data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                            shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_dim,out_dim,act_fn):\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(in_dim,out_dim, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(out_dim),\n",
    "        act_fn,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def conv_trans_block(in_dim,out_dim,act_fn):\n",
    "    model = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_dim,out_dim, kernel_size=3, stride=2, padding=1,output_padding=1),\n",
    "        nn.BatchNorm2d(out_dim),\n",
    "        act_fn,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def maxpool():\n",
    "    pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "    return pool\n",
    "\n",
    "\n",
    "def conv_block_2(in_dim,out_dim,act_fn):\n",
    "    model = nn.Sequential(\n",
    "        conv_block(in_dim,out_dim,act_fn),\n",
    "        nn.Conv2d(out_dim,out_dim, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(out_dim),\n",
    "    )\n",
    "    return model    \n",
    "\n",
    "\n",
    "def conv_block_3(in_dim,out_dim,act_fn):\n",
    "    model = nn.Sequential(\n",
    "        conv_block(in_dim,out_dim,act_fn),\n",
    "        conv_block(out_dim,out_dim,act_fn),\n",
    "        nn.Conv2d(out_dim,out_dim, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(out_dim),\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_residual_conv(nn.Module):\n",
    "\n",
    "    def __init__(self,in_dim,out_dim,act_fn):\n",
    "        super(Conv_residual_conv,self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        act_fn = act_fn\n",
    "\n",
    "        self.conv_1 = conv_block(self.in_dim,self.out_dim,act_fn)\n",
    "        self.conv_2 = conv_block_3(self.out_dim,self.out_dim,act_fn)\n",
    "        self.conv_3 = conv_block(self.out_dim,self.out_dim,act_fn)\n",
    "\n",
    "    def forward(self,input):\n",
    "        conv_1 = self.conv_1(input)\n",
    "        conv_2 = self.conv_2(conv_1)\n",
    "        res = conv_1 + conv_2\n",
    "        conv_3 = self.conv_3(res)\n",
    "        return conv_3\n",
    "\n",
    "\n",
    "class FusionGenerator(nn.Module):\n",
    "\n",
    "    def __init__(self,input_nc, output_nc, ngf):\n",
    "        super(FusionGenerator,self).__init__()\n",
    "        self.in_dim = input_nc\n",
    "        self.out_dim = ngf\n",
    "        self.final_out_dim = output_nc\n",
    "        act_fn = nn.LeakyReLU(0.2, inplace=True)\n",
    "        act_fn_2 = nn.ReLU()\n",
    "\n",
    "        print(\"\\n------Initiating FusionNet------\\n\")\n",
    "\n",
    "        # encoder\n",
    "\n",
    "        self.down_1 = Conv_residual_conv(self.in_dim, self.out_dim, act_fn)\n",
    "        self.pool_1 = maxpool()\n",
    "        self.down_2 = Conv_residual_conv(self.out_dim, self.out_dim * 2, act_fn)\n",
    "        self.pool_2 = maxpool()\n",
    "        self.down_3 = Conv_residual_conv(self.out_dim * 2, self.out_dim * 4, act_fn)\n",
    "        self.pool_3 = maxpool()\n",
    "        self.down_4 = Conv_residual_conv(self.out_dim * 4, self.out_dim * 8, act_fn)\n",
    "        self.pool_4 = maxpool()\n",
    "\n",
    "        # bridge\n",
    "\n",
    "        self.bridge = Conv_residual_conv(self.out_dim * 8, self.out_dim * 16, act_fn)\n",
    "\n",
    "        # decoder\n",
    "\n",
    "        self.deconv_1 = conv_trans_block(self.out_dim * 16, self.out_dim * 8, act_fn_2)\n",
    "        self.up_1 = Conv_residual_conv(self.out_dim * 8, self.out_dim * 8, act_fn_2)\n",
    "        self.deconv_2 = conv_trans_block(self.out_dim * 8, self.out_dim * 4, act_fn_2)\n",
    "        self.up_2 = Conv_residual_conv(self.out_dim * 4, self.out_dim * 4, act_fn_2)\n",
    "        self.deconv_3 = conv_trans_block(self.out_dim * 4, self.out_dim * 2, act_fn_2)\n",
    "        self.up_3 = Conv_residual_conv(self.out_dim * 2, self.out_dim * 2, act_fn_2)\n",
    "        self.deconv_4 = conv_trans_block(self.out_dim * 2, self.out_dim, act_fn_2)\n",
    "        self.up_4 = Conv_residual_conv(self.out_dim, self.out_dim, act_fn_2)\n",
    "\n",
    "        # output\n",
    "\n",
    "        self.out = nn.Conv2d(self.out_dim,self.final_out_dim, kernel_size=3, stride=1, padding=1)\n",
    "        self.out_2 = nn.Tanh()\n",
    "        '''\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv2d(self.out_dim,self.final_out_dim, kernel_size=3, stride=1, padding=1),\n",
    "            #nn.BatchNorm2d(self.final_out_dim),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        '''\n",
    "\n",
    "        # initialization\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.normal_(0.0, 0.02)\n",
    "                m.bias.data.fill_(0)\n",
    "            \n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.normal_(1.0, 0.02)\n",
    "                m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "    def forward(self,input):\n",
    "\n",
    "        down_1 = self.down_1(input)\n",
    "        pool_1 = self.pool_1(down_1)\n",
    "        down_2 = self.down_2(pool_1)\n",
    "        pool_2 = self.pool_2(down_2)\n",
    "        down_3 = self.down_3(pool_2)\n",
    "        pool_3 = self.pool_3(down_3)\n",
    "        down_4 = self.down_4(pool_3)\n",
    "        pool_4 = self.pool_4(down_4)\n",
    "\n",
    "        bridge = self.bridge(pool_4)\n",
    "\n",
    "        deconv_1 = self.deconv_1(bridge)\n",
    "        skip_1 = (deconv_1 + down_4)/2\n",
    "        up_1 = self.up_1(skip_1)\n",
    "        deconv_2 = self.deconv_2(up_1)\n",
    "        skip_2 = (deconv_2 + down_3)/2\n",
    "        up_2 = self.up_2(skip_2)\n",
    "        deconv_3 = self.deconv_3(up_2)\n",
    "        skip_3 = (deconv_3 + down_2)/2\n",
    "        up_3 = self.up_3(skip_3)\n",
    "        deconv_4 = self.deconv_4(up_3)\n",
    "        skip_4 = (deconv_4 + down_1)/2\n",
    "        up_4 = self.up_4(skip_4)\n",
    "\n",
    "        out = self.out(up_4)\n",
    "        out = self.out_2(out)\n",
    "        #out = torch.clamp(out, min=-1, max=1)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------Initiating FusionNet------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generator = nn.DataParallel(FusionGenerator(3,3,64),device_ids=[0]).cuda()\n",
    "recon_loss_func = nn.MSELoss()\n",
    "lr = 0.002\n",
    "gen_optimizer = torch.optim.Adam(generator.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import slack_notification as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Variable containing:\n",
      "1.00000e-02 *\n",
      "  7.5492\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type FusionGenerator. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type Conv_residual_conv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Variable containing:\n",
      "1.00000e-05 *\n",
      "  3.0392\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epoch = 10\n",
    "file = open('./fusionnet_mse_loss', 'w')\n",
    "for i in range(epoch):\n",
    "    for _, (images,img_masks) in enumerate(train_batch):\n",
    "        gen_optimizer.zero_grad()\n",
    "\n",
    "        x = Variable(images).cuda(0)\n",
    "        y_ = Variable(img_masks).cuda(0).float()\n",
    "        y = generator.forward(x)\n",
    "        \n",
    "        loss = recon_loss_func(y,y_)\n",
    "        file.write(str(loss)+\"\\n\")\n",
    "        loss.backward()\n",
    "        gen_optimizer.step()\n",
    "\n",
    "        if _ % 400 ==0:\n",
    "            print(i)\n",
    "            print(loss)\n",
    "            v_utils.save_image(x.cpu().data,\"./result_fusion/original_image_{}_{}.png\".format(i,_))\n",
    "            v_utils.save_image(y_.cpu().data,\"./result_fusion/label_image_{}_{}.png\".format(i,_))\n",
    "            v_utils.save_image(y.cpu().data,\"./result_fusion/gen_image_{}_{}.png\".format(i,_))\n",
    "            torch.save(generator,'./model_fusion/fusion_{}_{}.pkl'.format(i,_))    \n",
    "            torch.save(generator.state_dict(), './model_fusion_state/fusion_{}_{}.pkl'.format(i,_))\n",
    "            \n",
    "            sn.send_notification(text = 'finish: epoch {}, batch_idx {}'.format(i,_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = AirbusTestDataset(root_dir='./test/', transform=transforms.Compose([\n",
    "                                            transforms.ToPILImage(),\n",
    "                                            transforms.Resize(size=img_size),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            ]))\n",
    "test_batch = data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                            shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"./model_fusion/fusion_4_800.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_images = ['13703f040.jpg',\n",
    "                 '14715c06d.jpg',\n",
    "                 '33e0ff2d5.jpg',\n",
    "                 '4d4e09f2a.jpg',\n",
    "                 '877691df8.jpg',\n",
    "                 '8b909bb20.jpg',\n",
    "                 'a8d99130e.jpg',\n",
    "                 'ad55c3143.jpg',\n",
    "                 'c8260c541.jpg',\n",
    "                 'd6c7f17c7.jpg',\n",
    "                 'dc3e7c901.jpg',\n",
    "                 'e44dffe88.jpg',\n",
    "                 'ef87bad36.jpg',\n",
    "                 'f083256d8.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    index = 0\n",
    "    df = pd.DataFrame({'ImageId': [], 'EncodedPixels': []})\n",
    "    df = df[['ImageId', 'EncodedPixels']]\n",
    "    \n",
    "    for _, (image, image_paths) in enumerate(test_batch):\n",
    "        image = Variable(image)\n",
    "        outputs = (model(image).data).cpu().numpy()\n",
    "        for img_name, out_img in zip(image_paths, outputs):\n",
    "            if img_name in ignore_images:\n",
    "                continue\n",
    "            out_img = out_img.transpose(1,2,0)\n",
    "            out_img = np.maximum(out_img, 0)\n",
    "            out_img = np.minimum(out_img, 1)\n",
    "            out_gray = np.mean(out_img, axis=2)\n",
    "        \n",
    "            thresh = 0.2\n",
    "            max_pixel = 1\n",
    "            _, out_thresh = cv2.threshold(out_gray, thresh, max_pixel, cv2.THRESH_BINARY)\n",
    "        \n",
    "            out_thresh = cv2.resize(out_thresh, (768, 768))\n",
    "            rl = convert_runlength(out_thresh)\n",
    "            \n",
    "            df.loc[index] = [img_name, rl]\n",
    "            if index % 5000 == 0:\n",
    "                df.to_csv('submission_fusion.csv', header=True, index=False)\n",
    "                sn.send_notification(text='{} tests done'.format(index))\n",
    "            index += 1\n",
    "            \n",
    "    df.to_csv('submission_fusion.csv', header=True, index=False)\n",
    "    sn.send_notification(text='all done'.format(index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
